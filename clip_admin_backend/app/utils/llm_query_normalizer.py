"""
Normalizador sem√°ntico de queries usando Sentence Transformers (MiniLM)
Extrae color, tipo y contexto de la consulta del usuario DIN√ÅMICAMENTE desde BD del cliente.
USA EMBEDDINGS SEM√ÅNTICOS para matching flexible.
"""
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re

# Modelo liviano multiling√ºe
MODEL_NAME = 'paraphrase-multilingual-MiniLM-L12-v2'
_model = None

def get_model():
    global _model
    if _model is None:
        _model = SentenceTransformer(MODEL_NAME)
    return _model


def _extract_client_vocabulary(client_id: int) -> dict:
    """
    Extrae vocabulario din√°mico desde la BD del cliente

    Returns:
        dict con 'colores', 'colores_especificos', 'tipos', 'contextos' basados en datos reales
    """
    from app import db
    from app.models.category import Category
    from app.models.product import Product
    from sqlalchemy import text, func

    vocabulary = {
        'colores_especificos': set(),  # Colores de productos (azul, rojo, violeta)
        'colores_genericos': set(),    # Variaciones gen√©ricas (multicolor, colorido)
        'tipos': set(),
        'contextos': set()
    }

    # 1. COLORES ESPEC√çFICOS: Desde attributes->>'color' de productos del cliente
    try:
        color_rows = db.session.execute(
            text("""
                SELECT DISTINCT LOWER(TRIM(p.attributes->>'color')) as color
                FROM products p
                WHERE p.client_id = :client_id
                  AND p.attributes ? 'color'
                  AND NULLIF(TRIM(p.attributes->>'color'), '') IS NOT NULL
            """),
            {"client_id": client_id}
        ).fetchall()

        for row in color_rows:
            if row[0]:
                # Dividir si hay m√∫ltiples colores separados por comas/espacios
                colors = re.split(r'[,/\s]+', row[0].lower())
                for c in colors:
                    c_clean = c.strip()
                    if len(c_clean) > 2 and c_clean not in ['de', 'con', 'sin']:
                        vocabulary['colores_especificos'].add(c_clean)

    except Exception as e:
        print(f"‚ö†Ô∏è Error extrayendo colores: {e}")

    # Variaciones gen√©ricas (solo si NO hay color espec√≠fico en query)
    vocabulary['colores_genericos'] = {
        'multicolor', 'colorido', 'de colores', 'estampado', 'brillante',
        'oscuro', 'claro', 'pastel', 'mate', 'metalizado'
    }

    # 2. TIPOS: Desde nombres de categor√≠as del cliente
    try:
        categories = Category.query.filter_by(
            client_id=client_id,
            is_active=True
        ).all()

        for cat in categories:
            # Extraer palabras clave del nombre de categor√≠a
            # Ej: "GORROS ‚Äì GORRAS (HATS - CAPS)" ‚Üí ["gorros", "gorras", "hats", "caps"]
            # Eliminar s√≠mbolos y separar palabras
            clean_name = re.sub(r'[‚Äì\-()]+', ' ', cat.name.lower())
            words = re.findall(r'\b[a-z√°√©√≠√≥√∫√±]{3,}\b', clean_name)
            vocabulary['tipos'].update(words)

            # Tambi√©n agregar el nombre completo limpio
            if len(cat.name) > 3:
                vocabulary['tipos'].add(cat.name.lower().strip())

    except Exception as e:
        print(f"‚ö†Ô∏è Error extrayendo tipos: {e}")

    # 3. CONTEXTOS: Desde tags de productos del cliente
    try:
        products = Product.query.filter_by(client_id=client_id).all()

        for product in products:
            if product.tags:
                tags = [t.strip().lower() for t in product.tags.split(',')]
                vocabulary['contextos'].update(t for t in tags if len(t) > 2)

    except Exception as e:
        print(f"‚ö†Ô∏è Error extrayendo contextos: {e}")

    # Convertir sets a listas
    return {
        'colores': list(vocabulary['colores_especificos']),
        'tipos': list(vocabulary['tipos']),
        'contextos': list(vocabulary['contextos'])
    }


def _semantic_match(query: str, vocabulary: list, threshold: float = 0.5) -> str:
    """
    Encuentra la mejor coincidencia sem√°ntica usando embeddings del LLM.

    Args:
        query: Texto de b√∫squeda
        vocabulary: Lista de t√©rminos candidatos del cliente
        threshold: Similitud m√≠nima para considerar match (0-1)

    Returns:
        Mejor match o None si no supera threshold
    """
    if not vocabulary:
        return None

    model = get_model()

    # Encodear query y vocabulario
    query_emb = model.encode([query.lower()])
    vocab_embs = model.encode([v.lower() for v in vocabulary])

    # Calcular similitudes coseno
    similarities = cosine_similarity(query_emb, vocab_embs)[0]

    # Encontrar el mejor match
    max_idx = np.argmax(similarities)
    max_sim = similarities[max_idx]

    if max_sim >= threshold:
        print(f"  üéØ Match: '{query}' ‚Üí '{vocabulary[max_idx]}' (sim={max_sim:.3f})")
        return vocabulary[max_idx]

    return None


def _semantic_match_multiple(query: str, vocabulary: list, threshold: float = 0.4, top_k: int = 3) -> list:
    """
    Encuentra m√∫ltiples coincidencias sem√°nticas.

    Args:
        query: Texto de b√∫squeda
        vocabulary: Lista de t√©rminos candidatos
        threshold: Similitud m√≠nima
        top_k: M√°ximo de matches a retornar

    Returns:
        Lista de matches ordenados por similitud
    """
    if not vocabulary:
        return []

    model = get_model()

    # Encodear query y vocabulario
    query_emb = model.encode([query.lower()])
    vocab_embs = model.encode([v.lower() for v in vocabulary])

    # Calcular similitudes
    similarities = cosine_similarity(query_emb, vocab_embs)[0]

    # Filtrar por threshold y ordenar
    matches = []
    for idx, sim in enumerate(similarities):
        if sim >= threshold:
            matches.append((vocabulary[idx], sim))

    # Ordenar por similitud descendente y tomar top_k
    matches.sort(key=lambda x: x[1], reverse=True)

    if matches:
        print(f"  üéØ Matches contextos: {[(m[0], f'{m[1]:.3f}') for m in matches[:top_k]]}")

    return [match[0] for match in matches[:top_k]]


def _detect_ambiguous_terms(query: str, vocabulary: dict) -> dict:
    """
    Detecta t√©rminos gen√©ricos/ambiguos en la query y sugiere refinamientos.

    Args:
        query: Query del usuario
        vocabulary: Vocabulario del cliente (colores, tipos, contextos)

    Returns:
        dict con sugerencias de refinamiento si la query es ambigua
    """
    query_lower = query.lower()
    suggestions = {
        'is_ambiguous': False,
        'ambiguous_terms': [],
        'suggestions': {}
    }

    # Palabras gen√©ricas que indican necesidad de refinamiento
    generic_color_terms = ['color', 'colores', 'colorido', 'colorida']
    generic_style_terms = ['estilo', 'tipo', 'modelo', 'dise√±o']

    # Detectar si hay t√©rminos gen√©ricos
    for term in generic_color_terms:
        if term in query_lower:
            suggestions['is_ambiguous'] = True
            suggestions['ambiguous_terms'].append(term)
            # Sugerir colores disponibles del cliente
            if vocabulary.get('colores'):
                suggestions['suggestions']['colores'] = vocabulary['colores'][:8]  # Top 8

    for term in generic_style_terms:
        if term in query_lower:
            suggestions['is_ambiguous'] = True
            suggestions['ambiguous_terms'].append(term)
            # Sugerir contextos disponibles del cliente
            if vocabulary.get('contextos'):
                suggestions['suggestions']['contextos'] = vocabulary['contextos'][:8]

    return suggestions


def normalize_query(query: str, client_id: int = None) -> dict:
    """
    Extrae color, tipo y contexto de la consulta usando:
    - Vocabulario din√°mico del cliente (desde BD)
    - Matching sem√°ntico (LLM embeddings)

    Args:
        query: Texto de b√∫squeda del usuario
        client_id: ID del cliente para extraer vocabulario espec√≠fico

    Returns:
        dict: {'tipo': ..., 'color': ..., 'contexto': [...], 'query': ..., 'embedding': [...]}
    """
    query_lower = query.lower()
    model = get_model()
    emb = model.encode(query_lower)

    # Obtener vocabulario din√°mico del cliente
    if client_id:
        vocab = _extract_client_vocabulary(client_id)
        colores = vocab['colores']
        tipos = vocab['tipos']
        contextos = vocab['contextos']

        print(f"üìö VOCAB: {len(colores)} colores, {len(tipos)} tipos, {len(contextos)} contextos")
    else:
        # Fallback a listas m√≠nimas si no hay client_id
        colores = ['negro', 'blanco', 'azul', 'rojo', 'verde', 'amarillo', 'gris']
        tipos = ['delantal', 'camisa', 'pantalon', 'gorra', 'gorro']
        contextos = ['casual', 'formal', 'deportivo']

    # MATCHING SEM√ÅNTICO con LLM (no substring!)
    # Thresholds m√°s estrictos para evitar falsos positivos:
    # - Color: 0.65 (solo si el color est√° expl√≠cito: "gorra roja", "azul marino")
    # - Tipo: 0.60 (categor√≠a debe estar clara en la query)
    # - Contexto: 0.45 (m√°s flexible para estilos/ocasiones)
    color = _semantic_match(query, colores, threshold=0.65) if colores else None
    tipo = _semantic_match(query, tipos, threshold=0.60) if tipos else None
    contexto = _semantic_match_multiple(query, contextos, threshold=0.45, top_k=2) if contextos else []

    # Detectar queries ambiguas y generar sugerencias
    ambiguity_check = _detect_ambiguous_terms(query, vocab if client_id else {})

    result = {
        'tipo': tipo,
        'color': color,
        'contexto': contexto,
        'query': query,
        'embedding': emb.tolist()
    }

    # Agregar sugerencias si la query es ambigua
    if ambiguity_check['is_ambiguous']:
        result['needs_refinement'] = True
        result['ambiguous_terms'] = ambiguity_check['ambiguous_terms']
        result['suggestions'] = ambiguity_check['suggestions']
        print(f"üí° QUERY AMBIGUA detectada: {ambiguity_check['ambiguous_terms']}")
        print(f"   Sugerencias: {list(ambiguity_check['suggestions'].keys())}")
    else:
        result['needs_refinement'] = False

    return result


if __name__ == "__main__":
    # Prueba r√°pida
    ejemplos = [
        "delantal amarillo para cocina resistente a manchas",
        "camisa azul marino de invierno",
        "guardapolvo blanco escolar unisex",
        "vestido rosa casual verano",
        "pantalon negro industrial impermeable"
    ]
    for q in ejemplos:
        print(f"Query: {q}")
        print(normalize_query(q))
        print()
