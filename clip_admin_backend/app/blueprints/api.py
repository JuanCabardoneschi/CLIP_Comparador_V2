"""
Blueprint de API
Endpoints internos para el admin panel y b√∫squeda visual
"""

import time
import hashlib
import numpy as np
import torch
import os
from flask import Blueprint, request, jsonify, send_file
from flask_login import login_required, current_user
from flask_cors import CORS
from app import db
from app.models.client import Client
from app.models.category import Category
from app.models.product import Product
from app.models.image import Image
from app.models.search_log import SearchLog
from app.services.image_manager import image_manager
from sqlalchemy import func, or_
from googletrans import Translator

# üöÄ IMPORTAR CLIP AL INICIO PARA CACHE GLOBAL
from app.blueprints.embeddings import get_clip_model

bp = Blueprint("api", __name__)

# Habilitar CORS para este blueprint
CORS(bp, origins=["*"],
     methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
     allow_headers=["Content-Type", "X-API-Key", "Authorization"])


@bp.route("/image/<path:filename>")
def serve_image(filename):
    """Servir im√°genes directamente usando ImageManager"""
    try:
        # ‚úÖ USAR IMAGEMANAGER - Buscar imagen por filename
        from app.models.image import Image
        image = Image.query.filter_by(filename=filename).first()

        if not image:
            return "Image not found", 404

        # Obtener cliente din√°micamente
        client = image.client if hasattr(image, 'client') else None
        client_slug = client.slug if client else None

        # Usar ImageManager para obtener la ruta (auto-detecta si client_slug es None)
        image_path = image_manager.get_image_path(image, client_slug)

        if image_manager.image_exists(image, client_slug):
            return send_file(image_path)
        else:
            return "Image file not found", 404

    except Exception as e:
        return f"Error: {str(e)}", 500


@bp.route("/search/global")
@login_required
def global_search():
    """B√∫squeda global en todos los modelos"""
    query = request.args.get("q", "")
    if not query:
        return jsonify({"results": []})

    results = {
        "clients": [],
        "products": [],
        "categories": [],
        "images": []
    }

    # Buscar clientes
    clients = Client.query.filter(
        or_(Client.name.contains(query), Client.email.contains(query))
    ).limit(5).all()

    results["clients"] = [{
        "id": client.id,
        "name": client.name,
        "email": client.email,
        "type": "client"
    } for client in clients]

    # Buscar productos
    products = Product.query.filter(
        or_(
            Product.name.contains(query),
            Product.description.contains(query),
            Product.sku.contains(query)
        )
    ).limit(5).all()

    results["products"] = [{
        "id": product.id,
        "name": product.name,
        "sku": product.sku,
        "category": product.category.name,
        "type": "product"
    } for product in products]

    # Buscar categor√≠as
    categories = Category.query.filter(
        or_(Category.name.contains(query), Category.description.contains(query))
    ).limit(5).all()

    results["categories"] = [{
        "id": category.id,
        "name": category.name,
        "client": category.client.name,
        "type": "category"
    } for category in categories]

    # Buscar im√°genes
    images = Image.query.join(Product).filter(
        or_(
            Product.name.contains(query),
            Image.alt_text.contains(query),
            Image.original_filename.contains(query)
        )
    ).limit(5).all()

    results["images"] = [{
        "id": image.id,
        "product_name": image.product.name,
        "alt_text": image.alt_text,
        "url": image_manager.get_image_url(image),  # Auto-detecta client_slug
        "type": "image"
    } for image in images]

    return jsonify(results)


@bp.route("/stats/dashboard")
@login_required
def dashboard_stats():
    """Estad√≠sticas para el dashboard principal"""
    stats = {
        # Contadores principales
        "totals": {
            "clients": Client.query.count(),
            "categories": Category.query.count(),
            "products": Product.query.count(),
            "images": Image.query.count(),
            # "api_keys": APIKey.query.filter_by(is_active=True).count()  # Comentado - modelo no existe
        },

        # Actividad reciente
        "recent": {
            "new_clients_this_month": Client.query.filter(
                func.extract("month", Client.created_at) == func.extract("month", func.now())
            ).count(),
            "new_products_this_month": Product.query.filter(
                func.extract("month", Product.created_at) == func.extract("month", func.now())
            ).count(),
            "searches_today": SearchLog.query.filter(
                func.date(SearchLog.created_at) == func.current_date()
            ).count()
        },

        # Top categor√≠as por productos
        "top_categories": db.session.query(
            Category.name,
            Category.id,
            func.count(Product.id).label("product_count")
        ).outerjoin(Product).group_by(
            Category.id, Category.name
        ).order_by(func.count(Product.id).desc()).limit(5).all()
    }

    # Convertir resultados de SQLAlchemy a dict
    stats["top_categories"] = [{
        "name": cat.name,
        "id": cat.id,
        "product_count": cat.product_count
    } for cat in stats["top_categories"]]

    return jsonify(stats)


@bp.route("/validate/sku")
@login_required
def validate_sku():
    """Validar que un SKU sea √∫nico"""
    sku = request.args.get("sku")
    product_id = request.args.get("product_id")  # Para edici√≥n

    if not sku:
        return jsonify({"valid": False, "message": "SKU requerido"})

    query = Product.query.filter_by(sku=sku)
    if product_id:
        query = query.filter(Product.id != product_id)

    existing = query.first()

    return jsonify({
        "valid": existing is None,
        "message": "SKU disponible" if existing is None else "SKU ya existe"
    })


@bp.route("/validate/slug")
@login_required
def validate_slug():
    """Validar que un slug sea √∫nico dentro del cliente"""
    slug = request.args.get("slug")
    client_id = request.args.get("client_id")
    model_type = request.args.get("type")  # "category" o "product"
    item_id = request.args.get("item_id")  # Para edici√≥n

    if not slug or not client_id or not model_type:
        return jsonify({"valid": False, "message": "Par√°metros requeridos"})

    if model_type == "category":
        query = Category.query.filter_by(slug=slug, client_id=client_id)
        if item_id:
            query = query.filter(Category.id != item_id)
    elif model_type == "product":
        query = Product.query.join(Category).filter(
            Product.slug == slug,
            Category.client_id == client_id
        )
        if item_id:
            query = query.filter(Product.id != item_id)
    else:
        return jsonify({"valid": False, "message": "Tipo inv√°lido"})

    existing = query.first()

    return jsonify({
        "valid": existing is None,
        "message": "Slug disponible" if existing is None else "Slug ya existe"
    })


@bp.route("/bulk/delete", methods=["POST"])
@login_required
def bulk_delete():
    """Eliminaci√≥n en lote"""
    data = request.get_json()
    if not data:
        return jsonify({"success": False, "message": "Datos requeridos"})

    model_type = data.get("type")
    ids = data.get("ids", [])

    if not model_type or not ids:
        return jsonify({"success": False, "message": "Tipo e IDs requeridos"})

    try:
        deleted_count = 0

        if model_type == "products":
            # Eliminar productos
            for product_id in ids:
                product = Product.query.get(product_id)
                if product:
                    # Eliminar im√°genes asociadas
                    Image.query.filter_by(product_id=product_id).delete()
                    db.session.delete(product)
                    deleted_count += 1

        elif model_type == "categories":
            # Eliminar categor√≠as (solo si no tienen productos)
            for category_id in ids:
                category = Category.query.get(category_id)
                if category:
                    product_count = Product.query.filter_by(category_id=category_id).count()
                    if product_count == 0:
                        db.session.delete(category)
                        deleted_count += 1

        elif model_type == "images":
            # Eliminar im√°genes
            for image_id in ids:
                image = Image.query.get(image_id)
                if image:
                    # Usar ImageManager para eliminar la imagen (auto-detecta client_slug)
                    image_manager.delete_image(image)
                    deleted_count += 1

        db.session.commit()

        return jsonify({
            "success": True,
            "message": f"{deleted_count} elemento(s) eliminado(s)",
            "deleted_count": deleted_count
        })

    except Exception as e:
        db.session.rollback()
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}"
        })


@bp.route("/export/data")
@login_required
def export_data():
    """Exportar datos en formato JSON"""
    client_id = request.args.get("client_id")
    data_type = request.args.get("type", "all")

    export_data = {}

    if data_type in ["all", "clients"]:
        query = Client.query
        if client_id:
            query = query.filter_by(id=client_id)

        export_data["clients"] = [{
            "id": client.id,
            "name": client.name,
            "email": client.email,
            "description": client.description,
            "created_at": client.created_at.isoformat()
        } for client in query.all()]

    if data_type in ["all", "categories"]:
        query = Category.query
        if client_id:
            query = query.filter_by(client_id=client_id)

        export_data["categories"] = [{
            "id": category.id,
            "name": category.name,
            "slug": category.slug,
            "description": category.description,
            "client_id": category.client_id,
            "created_at": category.created_at.isoformat()
        } for category in query.all()]

    if data_type in ["all", "products"]:
        query = Product.query
        if client_id:
            query = query.join(Category).filter(Category.client_id == client_id)

        export_data["products"] = [{
            "id": product.id,
            "name": product.name,
            "slug": product.slug,
            "description": product.description,
            "price": product.price,
            "sku": product.sku,
            "category_id": product.category_id,
            "created_at": product.created_at.isoformat()
        } for product in query.all()]

    return jsonify(export_data)


@bp.route("/translate", methods=["POST"])
@login_required
def translate_text():
    """Traducir texto usando Google Translate"""
    try:
        data = request.get_json()
        text = data.get("text", "").strip()
        target_language = data.get("target_language", "en")

        if not text:
            return jsonify({
                "success": False,
                "error": "No se proporcion√≥ texto para traducir"
            })

        # Crear instancia del traductor
        translator = Translator()

        # Obtener el contexto de la industria del cliente
        industry_context = ""
        if current_user.client and current_user.client.industry:
            industry_context = current_user.client.industry.lower()

        # Traducir el texto
        translation = translator.translate(text, dest=target_language)
        translated_text = translation.text.lower()

        # Post-procesar basado en la industria (como en el modelo Category)
        if industry_context == "textil":
            textil_corrections = {
                'tablier': 'apron',
                'tabliers': 'aprons',
                'tabler': 'apron',
                'delantal': 'apron',
                'delantales': 'aprons',
                'uniforms': 'uniform',
                'uniformes': 'uniform',
                'gorras': 'hat',
                'gorros': 'hat',
                'gorra': 'hat',
                'gorro': 'hat',
                'caps': 'hat',
                'cap': 'hat',
                'shirts': 'shirt',
                'camisas': 'shirt',
                'camisa': 'shirt',
                'pants': 'pants',
                'pantalones': 'pants',
                'pantalon': 'pants',
                'trousers': 'pants'
            }

            for wrong, correct in textil_corrections.items():
                translated_text = translated_text.replace(wrong.lower(), correct.lower())

        return jsonify({
            "success": True,
            "translated_text": translated_text,
            "original_text": text,
            "target_language": target_language
        })

    except Exception as e:
        print(f"Error en traducci√≥n: {str(e)}")
        return jsonify({
            "success": False,
            "error": f"Error en la traducci√≥n: {str(e)}"
        })


@bp.errorhandler(404)
def api_not_found(error):
    return jsonify({"error": "Endpoint no encontrado"}), 404


# ==============================================================================
# ENDPOINT DE B√öSQUEDA VISUAL PARA WIDGET
# ==============================================================================

@bp.route("/test", methods=["GET", "OPTIONS"])
def test_endpoint():
    """Endpoint de prueba para verificar conectividad"""
    if request.method == 'OPTIONS':
        response = jsonify({'status': 'ok'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, X-API-Key'
        return response

    response = jsonify({
        "success": True,
        "message": "Endpoint funcionando correctamente",
        "timestamp": time.time()
    })
    response.headers['Access-Control-Allow-Origin'] = '*'
    return response

def verify_api_key():
    """Verificar API Key del header (simplificado para testing)"""
    api_key = request.headers.get('X-API-Key')
    if not api_key:
        return None, "API Key requerida en header X-API-Key"

    # Para testing, usar la API Key del cliente demo
    client = Client.query.filter_by(api_key=api_key, is_active=True).first()
    if not client:
        return None, "API Key inv√°lida"

    return client, None



def process_image_for_search(image_data):
    """Procesar imagen y generar embedding para b√∫squeda"""
    try:
        print("üîß DEBUG: Iniciando procesamiento de imagen")

        # Importar PIL con alias para evitar conflictos
        from PIL import Image as PILImage
        import io
        print("üîß DEBUG: Importaciones exitosas")

        # Convertir bytes a imagen PIL
        pil_image = PILImage.open(io.BytesIO(image_data))
        print(f"üîß DEBUG: Imagen PIL creada: {pil_image.size}")

        # Obtener modelo CLIP directamente
        start_clip_time = time.time()
        model, processor = get_clip_model()
        clip_load_time = time.time() - start_clip_time
        print(f"ÔøΩ CLIP MODEL: Obtenido en {clip_load_time:.3f}s")

        # Generar embedding usando solo argumentos necesarios
        print("üîß DEBUG: Llamando al procesador CLIP...")
        start_process_time = time.time()

        # Llamada simplificada al procesador
        with torch.no_grad():
            inputs = processor(
                images=pil_image,
                return_tensors="pt"
            )
            print("üîß DEBUG: Inputs del procesador creados exitosamente")

            # Generar features de imagen
            image_features = model.get_image_features(**inputs)
            print(f"üîß DEBUG: Image features generadas: {image_features.shape}")

            # Normalizar embedding
            embedding = image_features / image_features.norm(dim=-1, keepdim=True)

            # Convertir a lista de Python
            embedding_list = embedding.squeeze().cpu().numpy().tolist()
            
            process_time = time.time() - start_process_time
            print(f"‚ö° CLIP PROCESSING: Completado en {process_time:.3f}s")

        print(f"üîß DEBUG: Embedding generado exitosamente: {len(embedding_list)} dimensiones")
        return embedding_list, None

    except Exception as e:
        print(f"‚ùå DEBUG: Error en process_image_for_search: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, f"Error procesando imagen: {str(e)}"


def calculate_similarity(embedding1, embedding2):
    """Calcular similitud coseno entre embeddings"""
    if isinstance(embedding1, str):
        embedding1 = eval(embedding1)  # Convertir string a lista
    if isinstance(embedding2, str):
        embedding2 = eval(embedding2)

    embedding1 = np.array(embedding1)
    embedding2 = np.array(embedding2)

    # Normalizar
    embedding1 = embedding1 / np.linalg.norm(embedding1)
    embedding2 = embedding2 / np.linalg.norm(embedding2)

    # Similitud coseno
    similarity = np.dot(embedding1, embedding2)
    return float(similarity)


def _validate_visual_search_request():
    """Valida los par√°metros de la b√∫squeda visual"""
    # Verificar API Key
    client, error = verify_api_key()
    if error:
        return None, jsonify({
            "error": "unauthorized",
            "message": error
        }), 401

    # Verificar imagen
    if 'image' not in request.files:
        return None, jsonify({
            "error": "bad_request",
            "message": "Imagen requerida en form-data 'image'"
        }), 400

    image_file = request.files['image']
    if image_file.filename == '':
        return None, jsonify({
            "error": "bad_request",
            "message": "No se seleccion√≥ archivo"
        }), 400

    return client, image_file, None


def _process_image_data(image_file):
    """Procesa y valida los datos de la imagen"""
    # Par√°metros
    limit = min(int(request.form.get('limit', 3)), 10)
    threshold = float(request.form.get('threshold', 0.1))

    # Leer imagen
    image_data = image_file.read()

    # Validar tama√±o (15MB m√°ximo)
    if len(image_data) > 15 * 1024 * 1024:
        return None, None, None, jsonify({
            "error": "file_too_large",
            "message": "Imagen muy grande. M√°ximo 15MB"
        }), 400

    return image_data, limit, threshold, None, None


def _generate_query_embedding(image_data):
    """Genera el embedding de la imagen de consulta"""
    print(f"üì∑ DEBUG: Procesando imagen de {len(image_data)} bytes")
    query_embedding, error = process_image_for_search(image_data)
    if error:
        print(f"‚ùå DEBUG: Error en procesamiento: {error}")
        return None, jsonify({
            "error": "processing_failed",
            "message": error
        }), 500

    if query_embedding is None:
        print("‚ùå DEBUG: query_embedding es None")
        return None, jsonify({
            "error": "processing_failed",
            "message": "No se pudo generar embedding de la imagen"
        }), 500

    print(f"üß† DEBUG: Embedding generado - dimensiones: {len(query_embedding)}")
    print(f"üß† DEBUG: Primeros 5 valores: {query_embedding[:5]}")

    return query_embedding, None, None


def _find_similar_products(client, query_embedding, threshold):
    """Encuentra productos similares y agrupa por mejor coincidencia"""
    # Buscar im√°genes similares en la base de datos
    images = Image.query.filter_by(
        client_id=client.id,
        is_processed=True
    ).filter(Image.clip_embedding.isnot(None)).all()

    print(f"üîç DEBUG: Encontradas {len(images)} im√°genes para comparar")

    # Calcular similitudes y agrupar por producto
    product_best_match = {}  # Dict para almacenar la mejor imagen de cada producto
    category_similarities = {}  # Para determinar categor√≠a m√°s probable

    for img in images:
        try:
            similarity = calculate_similarity(query_embedding, img.clip_embedding)
            category_name = img.product.category.name if img.product.category else "Sin categor√≠a"

            print(f"üîç DEBUG: Similitud con {img.product.name[:30]} ({category_name}): {similarity:.4f}")

            # Recopilar estad√≠sticas por categor√≠a
            if category_name not in category_similarities:
                category_similarities[category_name] = []
            category_similarities[category_name].append(similarity)

            if similarity >= threshold:
                product_id = img.product.id

                # Si es la primera imagen de este producto, o si tiene mayor similitud que la anterior
                if product_id not in product_best_match or similarity > product_best_match[product_id]['similarity']:
                    product_best_match[product_id] = {
                        'image': img,
                        'similarity': similarity,
                        'product': img.product,
                        'category': category_name
                    }
                    print(f"‚úÖ DEBUG: Mejor imagen para {img.product.name}: {similarity:.4f}")

        except Exception as e:
            print(f"‚ùå Error calculando similitud para imagen {img.id}: {e}")
            continue

    # Determinar categor√≠a m√°s probable basada en mayor similitud promedio
    print(f"\nüìä DEBUG: An√°lisis por categor√≠as:")
    best_category = None
    best_avg_similarity = 0

    for category, similarities in category_similarities.items():
        avg_sim = sum(similarities) / len(similarities)
        max_sim = max(similarities)
        count = len(similarities)
        print(f"   üìÇ {category}: {count} productos, promedio: {avg_sim:.4f}, m√°ximo: {max_sim:.4f}")

        if max_sim > best_avg_similarity:  # Usar m√°ximo en lugar de promedio para detectar categor√≠a objetivo
            best_avg_similarity = max_sim
            best_category = category

    print(f"üéØ DEBUG: Categor√≠a m√°s probable: '{best_category}' (similitud m√°xima: {best_avg_similarity:.4f})")

    # Aplicar boost de categor√≠a: aumentar similitud para productos de la categor√≠a m√°s probable
    if best_category and best_category != "Sin categor√≠a":
        for product_id in product_best_match:
            match_data = product_best_match[product_id]
            if match_data['category'] == best_category:
                # Boost del 15% para productos de la misma categor√≠a
                original_similarity = match_data['similarity']
                boosted_similarity = min(1.0, original_similarity * 1.15)
                match_data['similarity'] = boosted_similarity
                match_data['category_boost'] = True
                print(f"üöÄ DEBUG: Boost aplicado a {match_data['product'].name}: {original_similarity:.4f} ‚Üí {boosted_similarity:.4f}")
            else:
                match_data['category_boost'] = False

    print(f"üéØ DEBUG: Productos √∫nicos encontrados: {len(product_best_match)}")
    return product_best_match


def _find_similar_products_in_category(client, query_embedding, threshold, category_id):
    """
    Encuentra productos similares SOLO dentro de una categor√≠a espec√≠fica

    Args:
        client: Cliente autenticado
        query_embedding: Embedding de la imagen query
        threshold: Umbral m√≠nimo de similitud
        category_id: ID de la categor√≠a en la que buscar

    Returns:
        dict: Diccionario con los mejores matches por producto
    """
    # Buscar im√°genes SOLO de la categor√≠a espec√≠fica
    images = (Image.query
              .join(Product)
              .filter(
                  Image.client_id == client.id,
                  Image.is_processed == True,
                  Image.clip_embedding.isnot(None),
                  Product.category_id == category_id
              ).all())

    print(f"üîç DEBUG: Encontradas {len(images)} im√°genes en la categor√≠a espec√≠fica")

    # Calcular similitudes y agrupar por producto
    product_best_match = {}  # Dict para almacenar la mejor imagen de cada producto

    for img in images:
        try:
            similarity = calculate_similarity(query_embedding, img.clip_embedding)
            category_name = img.product.category.name if img.product.category else "Sin categor√≠a"

            print(f"üîç DEBUG: Similitud con {img.product.name[:30]} ({category_name}): {similarity:.4f}")

            if similarity >= threshold:
                product_id = img.product.id

                # Si es la primera imagen de este producto, o si tiene mayor similitud que la anterior
                if product_id not in product_best_match or similarity > product_best_match[product_id]['similarity']:
                    product_best_match[product_id] = {
                        'image': img,
                        'similarity': similarity,
                        'product': img.product,
                        'category': category_name,
                        'category_filtered': True  # Indicador de que se filtr√≥ por categor√≠a
                    }
                    print(f"‚úÖ DEBUG: Mejor imagen para {img.product.name}: {similarity:.4f}")

        except Exception as e:
            print(f"‚ùå Error calculando similitud para imagen {img.id}: {e}")
            continue

    print(f"üéØ DEBUG: Total productos √∫nicos encontrados en categor√≠a: {len(product_best_match)}")
    return product_best_match


def _apply_category_filter(product_best_match, limit):
    """Aplica filtrado inteligente por categor√≠a si es necesario"""
    # Filtrado inteligente por categor√≠a (solo si hay suficientes productos)
    if len(product_best_match) <= limit * 2:  # Solo filtrar si hay muchos productos
        print(f"üéØ DEBUG: Pocos productos encontrados ({len(product_best_match)}), no se aplica filtro de categor√≠a")
        return product_best_match

    # Obtener las categor√≠as de los productos con mayor similitud
    sorted_products = sorted(product_best_match.items(), key=lambda x: x[1]['similarity'], reverse=True)

    # Tomar las top similitudes para determinar la categor√≠a dominante
    top_count = min(3, len(sorted_products))
    top_categories = {}

    for product_id, match_data in sorted_products[:top_count]:
        category_name = match_data['product'].category.name
        if category_name not in top_categories:
            top_categories[category_name] = []
        top_categories[category_name].append(match_data['similarity'])

    # Determinar la categor√≠a m√°s relevante basada en similitud promedio
    best_category = None
    best_avg_similarity = 0

    for category, similarities in top_categories.items():
        avg_similarity = sum(similarities) / len(similarities)
        print(f"üìÇ DEBUG: Categor√≠a '{category}': {len(similarities)} productos, similitud promedio: {avg_similarity:.4f}")

        if avg_similarity > best_avg_similarity:
            best_avg_similarity = avg_similarity
            best_category = category

    # Solo aplicar filtro si la categor√≠a dominante es muy clara (>60% similitud promedio)
    if not (best_category and best_avg_similarity > 0.6):
        print(f"üéØ DEBUG: No se aplic√≥ filtro de categor√≠a (similitud promedio: {best_avg_similarity:.4f})")
        return product_best_match

    print(f"üéØ DEBUG: Categor√≠a dominante detectada: '{best_category}' (similitud promedio: {best_avg_similarity:.4f})")

    # Filtrar solo productos de la categor√≠a dominante
    filtered_matches = {}
    for product_id, match_data in product_best_match.items():
        product_category = match_data['product'].category.name

        # Incluir productos de la categor√≠a dominante
        if product_category == best_category:
            filtered_matches[product_id] = match_data
            print(f"‚úÖ DEBUG: Incluido por categor√≠a exacta: {match_data['product'].name} ({product_category})")
        else:
            print(f"‚ùå DEBUG: Excluido por categor√≠a: {match_data['product'].name} ({product_category} != {best_category})")

    # Solo usar el filtro si queda al menos el m√≠nimo de productos
    if len(filtered_matches) >= limit:
        print(f"üéØ DEBUG: Productos despu√©s del filtro de categor√≠a: {len(filtered_matches)}")
        return filtered_matches
    else:
        print("‚ö†Ô∏è DEBUG: El filtro de categor√≠a elimin√≥ demasiados productos, manteniendo los originales")
        return product_best_match


def _build_search_results(product_best_match, limit):
    """Construye la lista final de resultados"""
    results = []
    for product_id, best_match in product_best_match.items():
        img = best_match['image']
        product = best_match['product']
        similarity = best_match['similarity']
        category_boost = best_match.get('category_boost', False)

        # Usar base64_data directamente del modelo Image
        try:
            if img.base64_data:
                image_url = img.base64_data
            elif img.cloudinary_url:
                # Fallback: usar URL de Cloudinary si no hay base64
                image_url = img.cloudinary_url
            else:
                image_url = None
        except Exception as e:
            print(f"‚ùå Error obteniendo imagen {img.filename}: {e}")
            image_url = None

        result = {
            "product_id": product.id,
            "name": product.name,
            "description": product.description or "Sin descripci√≥n",
            "image_url": image_url,
            "similarity": round(similarity, 4),
            "price": float(product.price) if product.price else None,
            "sku": product.sku,
            "stock": product.stock if hasattr(product, 'stock') and product.stock is not None else 0,
            "category": product.category.name if product.category else "Sin categor√≠a",
            "category_boost": category_boost
        }
        results.append(result)

        boost_indicator = "üöÄ" if category_boost else ""
        print(f"üì¶ DEBUG: Producto final a√±adido: {product.name} (similitud: {similarity:.4f}) {boost_indicator}")

    print(f"üéØ DEBUG: Total productos √∫nicos procesados: {len(results)}")

    # Ordenar por similitud y limitar resultados
    results.sort(key=lambda x: x['similarity'], reverse=True)
    return results[:limit]


def detect_general_object(image_data):
    """
    Detecta QU√â es el objeto en la imagen usando CLIP con categor√≠as generales
    
    Args:
        image_data: Datos binarios de la imagen
        
    Returns:
        tuple: (objeto_detectado, confidence_score)
    """
    try:
        # Categor√≠as generales para identificar objetos
        general_categories = [
            "car", "automobile", "vehicle",
            "hat", "cap", "beanie", "gorra", 
            "shoe", "boot", "sneaker", "zapato",
            "shirt", "t-shirt", "clothing", "camisa",
            "jacket", "coat", "chaqueta",
            "food", "comida", "meal",
            "animal", "pet", "dog", "cat",
            "electronics", "phone", "computer",
            "furniture", "chair", "table",
            "building", "house", "architecture",
            "person", "human", "people",
            "nature", "tree", "flower", "landscape"
        ]
        
        # Convertir a imagen PIL
        from PIL import Image as PILImage
        import io
        pil_image = PILImage.open(io.BytesIO(image_data))
        
        # Obtener modelo CLIP
        model, processor = get_clip_model()
        
        # Generar embedding de imagen
        with torch.no_grad():
            image_inputs = processor(images=pil_image, return_tensors="pt")
            image_features = model.get_image_features(**image_inputs)
            image_embedding = image_features / image_features.norm(dim=-1, keepdim=True)
            
            # Generar embeddings de texto para categor√≠as generales
            text_inputs = processor(text=general_categories, return_tensors="pt", padding=True)
            text_features = model.get_text_features(**text_inputs)
            text_embeddings = text_features / text_features.norm(dim=-1, keepdim=True)
            
            # Calcular similitudes
            similarities = torch.cosine_similarity(image_embedding, text_embeddings, dim=1)
            
            # Encontrar la mejor coincidencia
            best_idx = similarities.argmax().item()
            best_score = similarities[best_idx].item()
            detected_object = general_categories[best_idx]
            
            print(f"üîç DETECCI√ìN GENERAL: {detected_object} (confianza: {best_score:.3f})")
            
            return detected_object, best_score
            
    except Exception as e:
        print(f"‚ùå Error en detecci√≥n general: {e}")
        return "unknown", 0.0


def detect_image_category_with_centroids(image_data, client_id, confidence_threshold=0.2):
    """
    Detecta la categor√≠a de una imagen usando centroides de embeddings reales

    En lugar de prompts de texto, usa el promedio de embeddings de productos
    existentes en cada categor√≠a como "representante" de esa categor√≠a.

    Args:
        image_data: Datos binarios de la imagen
        client_id: ID del cliente para obtener sus categor√≠as
        confidence_threshold: Umbral m√≠nimo de confianza para detecci√≥n

    Returns:
        tuple: (categoria_detectada, confidence_score) o (None, 0) si no detecta
    """
    try:
        print(f"üöÄ RAILWAY LOG: Iniciando detecci√≥n centroides para cliente {client_id}")

        # 1. Obtener categor√≠as activas del cliente
        categories = Category.query.filter_by(
            client_id=client_id,
            is_active=True
        ).all()

        if not categories:
            print(f"‚ùå RAILWAY LOG: No categor√≠as para cliente {client_id}")
            return None, 0

        print(f"üìã RAILWAY LOG: {len(categories)} categor√≠as encontradas")

        # 2. Generar embedding de la imagen nueva
        from PIL import Image as PILImage
        import io
        pil_image = PILImage.open(io.BytesIO(image_data))
        print(f"üñºÔ∏è DEBUG: Imagen preparada: {pil_image.size}")

        # 3. Obtener modelo CLIP
        model, processor = get_clip_model()
        print("ü§ñ DEBUG: Modelo CLIP obtenido")

        # 4. Generar embedding de imagen nueva
        with torch.no_grad():
            image_inputs = processor(
                images=pil_image,
                return_tensors="pt"
            )
            image_features = model.get_image_features(**image_inputs)
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
            new_embedding = image_features.squeeze(0).numpy()

        print(f"üîç DEBUG: Embedding generado: shape {new_embedding.shape}")

        # 5. Calcular similitudes contra centroides de cada categor√≠a
        category_similarities = []

        for category in categories:
            # üöÄ USAR CENTROIDE DE BD DIRECTAMENTE
            centroid = category.get_centroid_embedding(auto_calculate=False)
            print(f"üîç RAILWAY LOG: {category.name} - centroide {'OK' if centroid is not None else 'NULL'}")

            if centroid is not None:
                # Calcular similitud coseno
                similarity = np.dot(new_embedding, centroid) / (np.linalg.norm(new_embedding) * np.linalg.norm(centroid))
                category_similarities.append({
                    'category': category,
                    'similarity': float(similarity)
                })
                print(f"üìä RAILWAY LOG: {category.name}: similitud {similarity:.4f}")
            else:
                print(f"‚ö†Ô∏è RAILWAY LOG: {category.name} SIN CENTROIDE en BD")

        if not category_similarities:
            print(f"‚ùå RAILWAY LOG: NO HAY SIMILITUDES - sin centroides v√°lidos")
            return None, 0

        # 6. Encontrar la mejor coincidencia
        best_match = max(category_similarities, key=lambda x: x['similarity'])
        best_category = best_match['category']
        best_score = best_match['similarity']

        print(f"üéØ RAILWAY LOG: MEJOR: {best_category.name} = {best_score:.4f}")

        # 7. Verificar umbral de confianza
        if best_score >= confidence_threshold:
            print(f"‚úÖ RAILWAY LOG: DETECTADO - {best_category.name} (conf: {best_score:.4f})")
            return best_category, best_score
        else:
            print(f"‚ùå RAILWAY LOG: RECHAZADO - {best_score:.4f} < {confidence_threshold}")
            return None, best_score

    except Exception as e:
        print(f"‚ùå ERROR en detecci√≥n por centroides: {e}")
        import traceback
        traceback.print_exc()
        return None, 0


def detect_image_category(image_data, client_id, confidence_threshold=0.2):
    """
    Funci√≥n de detecci√≥n por prompts (obsoleta, usa centroides como fallback)
    """
    try:
        print(f"üéØ DEBUG: Usando m√©todo de centroides en lugar de prompts")
        return detect_image_category_with_centroids(image_data, client_id, confidence_threshold)

    except Exception as e:
        print(f"‚ùå ERROR en detecci√≥n de categor√≠a: {e}")
        import traceback
        traceback.print_exc()
        return None, 0


def detect_image_category(image_data, client_id, confidence_threshold=0.2):
    """
    Detecta la categor√≠a de una imagen usando CLIP y los prompts de categor√≠as del cliente

    Args:
        image_data: Datos binarios de la imagen
        client_id: ID del cliente para obtener sus categor√≠as
        confidence_threshold: Umbral m√≠nimo de confianza para detecci√≥n

    Returns:
        tuple: (categoria_detectada, confidence_score) o (None, 0) si no detecta
    """
    try:
        print(f"üéØ DEBUG: Iniciando detecci√≥n de categor√≠a para cliente {client_id}")

        # 1. Obtener categor√≠as activas del cliente
        categories = Category.query.filter_by(
            client_id=client_id,
            is_active=True
        ).all()

        if not categories:
            print(f"‚ùå DEBUG: No se encontraron categor√≠as para cliente {client_id}")
            return None, 0

        print(f"üìã DEBUG: Encontradas {len(categories)} categor√≠as activas")

        # 2. Preparar imagen para CLIP
        from PIL import Image as PILImage
        import io
        pil_image = PILImage.open(io.BytesIO(image_data))
        print(f"üñºÔ∏è DEBUG: Imagen preparada: {pil_image.size}")

        # 3. Obtener modelo CLIP
        model, processor = get_clip_model()
        print("ü§ñ DEBUG: Modelo CLIP obtenido")

        # 4. Preparar prompts de categor√≠as
        category_prompts = []
        category_objects = []

        for category in categories:
            # Usar clip_prompt si existe, sino usar name_en, sino name
            if category.clip_prompt:
                prompt = f"a photo of {category.clip_prompt}"
            elif category.name_en:
                prompt = f"a photo of {category.name_en.lower()}"
            else:
                prompt = f"a photo of {category.name.lower()}"

            category_prompts.append(prompt)
            category_objects.append(category)
            print(f"üìù DEBUG: Prompt para {category.name}: {prompt}")

        # 5. Procesar imagen y textos con CLIP
        with torch.no_grad():
            # Procesar imagen
            image_inputs = processor(
                images=pil_image,
                return_tensors="pt"
            )
            image_features = model.get_image_features(**image_inputs)
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)

            # Procesar textos
            text_inputs = processor(
                text=category_prompts,
                return_tensors="pt",
                padding=True,
                truncation=True
            )
            text_features = model.get_text_features(**text_inputs)
            text_features = text_features / text_features.norm(dim=-1, keepdim=True)

            # Calcular similitudes
            similarities = (image_features @ text_features.T).squeeze(0)

            print(f"üîç DEBUG: Similitudes calculadas: {similarities.tolist()}")

        # 6. Encontrar la mejor coincidencia
        best_idx = similarities.argmax().item()
        best_score = similarities[best_idx].item()
        best_category = category_objects[best_idx]

        print(f"üéØ DEBUG: Mejor coincidencia: {best_category.name} ({best_score:.4f})")

        # 7. Verificar umbral de confianza
        if best_score >= confidence_threshold:
            print(f"‚úÖ DEBUG: Categor√≠a detectada con confianza suficiente")
            return best_category, best_score
        else:
            print(f"‚ùå DEBUG: Confianza insuficiente ({best_score:.4f} < {confidence_threshold})")
            return None, best_score

    except Exception as e:
        print(f"‚ùå ERROR en detecci√≥n de categor√≠a: {e}")
        import traceback
        traceback.print_exc()
        return None, 0


@bp.route("/search", methods=["POST", "OPTIONS"])
def visual_search():
    """
    Endpoint de b√∫squeda visual para el widget con detecci√≥n autom√°tica de categor√≠a

    Headers:
        X-API-Key: API Key del cliente

    Form Data:
        image: Archivo de imagen
        limit: N√∫mero de resultados (default: 3, max: 10)
        threshold: Umbral de similitud (default: 0.1)
    """
    # Manejar preflight OPTIONS request
    if request.method == 'OPTIONS':
        response = jsonify({'status': 'ok'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, X-API-Key'
        return response

    start_time = time.time()

    try:
        # Validar request
        client, image_file, error_response = _validate_visual_search_request()
        if error_response:
            return error_response

        # Procesar datos de imagen
        image_data, limit, _, error_response, status_code = _process_image_data(image_file)
        if error_response:
            return error_response, status_code

        # Sensibilidad personalizada por cliente
        category_confidence_threshold = (getattr(client, 'category_confidence_threshold', 70) or 70) / 100.0
        product_similarity_threshold = (getattr(client, 'product_similarity_threshold', 30) or 30) / 100.0

        # ===== PASO 1: DETECCI√ìN GENERAL DEL OBJETO =====
        print(f"üîç RAILWAY LOG: IDENTIFICANDO QU√â ES EL OBJETO...")

        detected_object, object_confidence = detect_general_object(image_data)
        print(f"üéØ RAILWAY LOG: OBJETO DETECTADO = {detected_object} (confianza: {object_confidence:.3f})")

        # Mapeo de objetos detectados a si los comercializamos
        commercial_keywords = [
            "hat", "cap", "beanie", "gorra",
            "shoe", "boot", "sneaker", "zapato", 
            "shirt", "t-shirt", "clothing", "camisa",
            "jacket", "coat", "chaqueta"
        ]

        # Verificar si el objeto detectado es comercializable
        is_commercial = detected_object in commercial_keywords
        
        if not is_commercial and object_confidence > 0.6:
            # El objeto est√° claramente identificado pero no lo comercializamos
            print(f"‚ùå RAILWAY LOG: OBJETO NO COMERCIAL - {detected_object}")
            return jsonify({
                "success": False,
                "error": "non_commercial_object",
                "message": f"Esta imagen contiene un {detected_object} que no comercializamos",
                "details": f"Detectamos que es un '{detected_object}' con {object_confidence:.1%} de confianza, pero no vendemos este tipo de productos.",
                "available_categories": [cat.name for cat in Category.query.filter_by(client_id=client.id, is_active=True).all()],
                "processing_time": round(time.time() - start_time, 3)
            }), 400

        # ===== PASO 2: DETECCI√ìN DE CATEGOR√çA ESPEC√çFICA =====
        print(f"üöÄ RAILWAY LOG: INICIANDO DETECCI√ìN DE CATEGOR√çA ESPEC√çFICA")

        detected_category, category_confidence = detect_image_category_with_centroids(
            image_data,
            client.id,
            confidence_threshold=category_confidence_threshold  # Sensibilidad por cliente
        )

        print(f"üéØ RAILWAY LOG: Resultado detecci√≥n = {detected_category.name if detected_category else 'NULL'} (conf: {category_confidence:.3f})")

        if detected_category is None:
            # No se pudo detectar una categor√≠a v√°lida
            print(f"‚ùå RAILWAY LOG: CATEGOR√çA NO DETECTADA - devolviendo error")
            return jsonify({
                "success": False,
                "error": "category_not_detected", 
                "message": f"Esta imagen no corresponde a productos que comercializa {client.name}",
                "details": f"La imagen no pudo identificarse dentro de nuestras categor√≠as disponibles (confianza m√°xima: {category_confidence:.1%}). Por favor, intenta con una imagen de un producto de nuestro cat√°logo.",
                "available_categories": [cat.name for cat in Category.query.filter_by(client_id=client.id, is_active=True).all()],
                "processing_time": round(time.time() - start_time, 3)
            }), 400

        print(f"‚úÖ RAILWAY LOG: CATEGOR√çA OK: {detected_category.name} - procediendo a b√∫squeda")

        # ===== GENERAR EMBEDDING DE LA IMAGEN =====
        query_embedding, error_response, status_code = _generate_query_embedding(image_data)
        if error_response:
            print(f"‚ùå RAILWAY LOG: Error generando embedding")
            return error_response, status_code

        # ===== BUSCAR SOLO EN LA CATEGOR√çA DETECTADA =====
        print(f"üîç RAILWAY LOG: Buscando productos en {detected_category.name}")

        # Modificar la b√∫squeda para filtrar por categor√≠a detectada
        product_best_match = _find_similar_products_in_category(
            client,
            query_embedding,
            product_similarity_threshold,
            detected_category.id
        )

        print(f"üéØ DEBUG: Productos encontrados en categor√≠a {detected_category.name}: {len(product_best_match)}")

        # Construir resultados finales (sin filtro adicional de categor√≠a)
        results = _build_search_results(product_best_match, limit)

        processing_time = time.time() - start_time

        # Respuesta con informaci√≥n de categor√≠a detectada
        response = {
            "success": True,
            "query_type": "image_with_category_detection",
            "detected_category": {
                "id": detected_category.id,
                "name": detected_category.name,
                "name_en": detected_category.name_en,
                "confidence": round(category_confidence, 4)
            },
            "query_info": {
                "method": "category_detection_with_clip",
                "detected_category": detected_category.name,
                "confidence": round(category_confidence, 4),
                "threshold_used": threshold,
                "category_filter": True
            },
            "results": results,
            "total_results": len(results),
            "processing_time": round(processing_time, 3),
            "client_id": client.id,
            "client_name": client.name,
            "search_method": "category_filtered",
            "timestamp": time.time()
        }

        # Headers CORS para widget
        response_obj = jsonify(response)
        response_obj.headers['Access-Control-Allow-Origin'] = '*'
        response_obj.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response_obj.headers['Access-Control-Allow-Headers'] = 'Content-Type, X-API-Key'

        return response_obj

    except Exception as e:
        processing_time = time.time() - start_time
        return jsonify({
            "error": "internal_error",
            "message": f"Error interno: {str(e)}",
            "processing_time": round(processing_time, 3)
        }), 500


@bp.route("/search", methods=["OPTIONS"])
def visual_search_options():
    """CORS preflight para el endpoint de b√∫squeda"""
    response = jsonify({"message": "OK"})
    response.headers['Access-Control-Allow-Origin'] = '*'
    response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
    response.headers['Access-Control-Allow-Headers'] = 'Content-Type, X-API-Key'
    return response


@bp.errorhandler(500)
def api_internal_error(error):
    return jsonify({"error": "Error interno del servidor"}), 500
